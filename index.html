<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Bo Ai</title>
  
  <meta name="author" content="Bo Ai">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<!--	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">-->
  <link rel="icon" href="general_images/nus-logo-small.png">
<!--  <a href="images/linkedin-pic.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/linkedin-pic.jpeg" class="hoverZoomLink"></a>-->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Bo Ai</name>
              </p>
              <p>
                I am a fourth-year undergraduate student in Computer Science and Statistics at the <a href="https://ai.google/research">National University of Singapore</a>. I work at the intersection of robotics, machine learning, and computer vision.
              </p>
              <p>
                Currently, I seek to endow robots with human-like navigation capabilities. I am advised by Prof <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a> at the <a href="https://adacomp.comp.nus.edu.sg/">Adaptive Computing Laboratory</a>. In my earlier years, I worked on video-based action recognition with Prof <a href="https://www.comp.nus.edu.sg/~ayao/">Angela Yao</a>. I received the <a href="https://www.comp.nus.edu.sg/news/2022-ourp-ocp-2122/">NUS Outstanding Undergraduate Research Prize</a> and the <a href="https://www.comp.nus.edu.sg/entrepreneurship/awards/iawinners/">NUS School of Computing Innovation Prize</a> in 2022.
              </p>
              <p style="text-align:center">
                <a href="mailto:bo.ai@u.nus.edu">Email</a> &nbsp/&nbsp
<!--                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp-->
<!--                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.com/citations?user=KlE77HAAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
<!--                <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp-->
                <a href="https://github.com/BoAi01">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="general_images/linkedin-pic.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="general_images/linkedin-pic.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am passionate about robotics, machine learning, and computer vision. I have been focusing on enabling robot to navigate across diverse environments with minial local sensing and prior global information of the environment, just like humans do. To this end, I enable robots to reason by integrating learning and planning, and to act robustly in the real world through learning generalizable representations, large-scale training, and sim-to-real transfer.

                Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<!-- highlighted papers should use bgcolor="#ffffd0" -->

<tr onmouseout="decision_start()" onmouseover="decision_start()"  bgcolor="#ffffd0">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='decision_image'><video  width=100% height=100% muted autoplay loop>
      <source src="projects/decision/decision-demo.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
<!--      <img src='projects/decision/decision-cover.jpeg' width=100% height=56%>-->
    </div>
    <script type="text/javascript">
      function decision_start() {
        document.getElementById('decision_image').style.opacity = "1";
      }

      function decision_stop() {
        document.getElementById('decision_image').style.opacity = "0";
      }
      decision_start()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://adacomp.comp.nus.edu.sg/inet/">
      <papertitle>Deep Visual Navigation under Partial Observability</papertitle>
    </a>
    <br>
    <strong>Bo Ai</strong>,
    <a href="https://www.linkedin.com/in/wei-gao-9526a477/?originalSubdomain=sg">Wei Gao</a>,
    <a href="https://connect.vin/about/">Vinay</a>,
    <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a>
    <br>
    <em>International Conference on Robotics and Automation (ICRA)</em>, 2022
    <br>
    <a href="https://adacomp.comp.nus.edu.sg/inet/">project page</a>
    /
    <a href="https://arxiv.org/abs/2109.07752">paper</a>
    /
    <a href="https://www.youtube.com/watch?v=N0wa04ZPZN0">demo</a>
    <p></p>
    <p>
    We end-to-end learned a controller that enables our Spot robot to navigate across varied environments with complex multimodal behaviors under partial observations.
    </p>
  </td>
</tr>

<tr onmouseout="contrax_stop()" onmouseover="contrax_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='contrax_image'><video width=100% height=100% muted autoplay loop>
      <source src="" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <img src='projects/contrax/visualization.png' width=100%>
    </div>
    <script type="text/javascript">
      function decision_start() {
        document.getElementById('decision_image').style.opacity = "1";
      }

      function decision_stop() {
        document.getElementById('decision_image').style.opacity = "0";
      }
      decision_start()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://aclanthology.org/2022.aacl-main.84">
      <papertitle>Whodunit? Learning to Contrast for Authorship Attribution</papertitle>
    </a>
    <br>
    <strong>Bo Ai</strong>, Yuchen Wang,
    <a href="https://www.linkedin.com/in/yugin-tan-1479461a4/?originalSubdomain=sg">Yugin Tan</a>,
    <a href="https://samsontmr.github.io/">Samson Tan</a>
    <br>
    <em>Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and International Joint Conference on Natural Language Processing (Long Paper)</em>, 2022
    <br>
<!--    <a href="https://adacomp.comp.nus.edu.sg/inet/">project page</a>-->
<!--    /-->
    <a href="https://aclanthology.org/2022.aacl-main.84/">paper</a>
    /
    <a href="https://www.youtube.com/watch?v=DpT181KgYlI">talk</a>
    <p></p>
    <p>
    We end-to-end learned a controller that enables our Spot robot to navigate across varied environments with complex multimodal behaviors under partial observations.
    </p>
  </td>
</tr>

<!--<tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">-->
<!--  <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--    <div class="one">-->
<!--      <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>-->
<!--      <source src="images/dreamfusion.mp4" type="video/mp4">-->
<!--      Your browser does not support the video tag.-->
<!--      </video></div>-->
<!--      <img src='images/dreamfusion.jpg' width="160">-->
<!--    </div>-->
<!--    <script type="text/javascript">-->
<!--      function dreamfusion_start() {-->
<!--        document.getElementById('dreamfusion_image').style.opacity = "1";-->
<!--      }-->

<!--      function dreamfusion_stop() {-->
<!--        document.getElementById('dreamfusion_image').style.opacity = "0";-->
<!--      }-->
<!--      dreamfusion_stop()-->
<!--    </script>-->
<!--  </td>-->
<!--  <td style="padding:20px;width:75%;vertical-align:middle">-->
<!--    <a href="https://dreamfusion3d.github.io/">-->
<!--      <papertitle>DreamFusion: Text-to-3D using 2D Diffusion</papertitle>-->
<!--    </a>-->
<!--    <br>-->
<!--    <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,-->
<!--    <a href="https://www.ajayj.com/">Ajay Jain</a>,-->
<!--    <strong>Jonathan T. Barron</strong>,-->
<!--		<a href="https://bmild.github.io/">Ben Mildenhall</a>-->
<!--    <br>-->
<!--    <em>ICLR</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>-->
<!--    <br>-->
<!--    <a href="https://dreamfusion3d.github.io/">project page</a>-->
<!--    /-->
<!--    <a href="https://arxiv.org/abs/2209.14988">arXiv</a>-->
<!--    /-->
<!--    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a>-->
<!--    <p></p>-->
<!--    <p>-->
<!--    We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling.-->
<!--    </p>-->
<!--  </td>-->
<!--</tr>-->
<!--		  -->
<!--          <tr onmouseout="mira_stop()" onmouseover="mira_start()">-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <div class="one">-->
<!--                <div class="two" id='mira_image'>-->
<!--                  <img src='images/mira_after.jpg' width="160"></div>-->
<!--                <img src='images/mira_before.jpg' width="160">-->
<!--              </div>-->
<!--              <script type="text/javascript">-->
<!--                function mira_start() {-->
<!--                  document.getElementById('mira_image').style.opacity = "1";-->
<!--                }-->

<!--                function mira_stop() {-->
<!--                  document.getElementById('mira_image').style.opacity = "0";-->
<!--                }-->
<!--                mira_stop()-->
<!--              </script>-->
<!--            </td>-->
<!--            <td style="padding:20px;width:75%;vertical-align:middle">-->
<!--              <a href="https://openreview.net/forum?id=AmPeAFzU3a4">-->
<!--                <papertitle>MIRA: Mental Imagery for Robotic Affordances</papertitle>-->
<!--              </a>-->
<!--              <br>-->
<!--              <a href="https://yenchenlin.me/">Lin Yen-Chen</a>,-->
<!--              <a href="http://www.peteflorence.com/">Pete Florence</a>,-->
<!--              <a href="https://andyzeng.github.io/">Andy Zeng</a>, <strong>Jonathan T. Barron</strong>,-->
<!--              <a href="https://yilundu.github.io/">Yilun Du</a>,-->
<!--              <a href="https://people.csail.mit.edu/weichium/">Wei-Chiu Ma</a>,-->
<!--              <a href="https://anthonysimeonov.github.io/">Anthony Simeonov</a>,-->
<!--              <a href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>,-->
<!--              <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>-->
<!--              <br>-->
<!--              <em>CoRL</em>, 2022-->
<!--              <p></p>-->
<!--              <p>-->
<!--                NeRF lets us synthesize novel orthographic views that work well with pixel-wise algorithms for robotic manipulation.-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->

        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Academic Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="general_images/ieee-ras-logo.png" width="100%"></td>
            <td width="75%" valign="center">
              Conference Reviewer, IROS 2023, ICRA 2023, ICRA 2022, IROS 2022
              </br>
              Journal Reviewer, RA-L
            </td>
          </tr>

        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="general_images/nus-soc-logo.jpeg" width="100%"></td>
            <td width="75%" valign="center">
              Teaching Assistant
              </br>
              CS1101S Programming Methodology, Fall 2020
              </br>
              <a href="https://knmnyn.github.io/cs3244-2210/">CS3244 Machine Learning, Fall 2022</a>
              </br>
              CS5478 Intelligent Robots: Algorithms and Systems, Spring 2023
            </td>
          </tr>

        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Awards and Honors</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="100%" valign="center">
            2022: Dean‚Äôs List (5%), NUS School of Computing (SoC) </br>
            2022: Global Young Scientists Summit 2023, Singapore National Research Foundation </br>
            2022: NUS Outstanding Undergraduate Researcher Prize (0.4%), NUS </br>
            2022: NUS School of Computing Innovation Prize (0.2%), NUS SoC & Singapore Computer Society </br>
            2022: Certificate of Distinction in AI, NUS SoC </br>
            2022: Certificate for Top Students x 2, NUS SoC </br>
            2021: Certificate for Top Students x 1, NUS SoC </br>
            2018: NUS Science and Technology Scholarship (~150K USD), NUS & Singapore Ministry of Education </br>

<!--            <td style="padding:20px;width:25%;vertical-align:middle"><img src="general_images/nus-soc-logo.jpeg" width="100%"></td>-->
<!--            <td width="75%" valign="center">-->
<!--              Teaching Assistant-->
<!--              </br>-->
<!--              CS1101S Programming Methodology, Fall 2020-->
<!--              </br>-->
<!--              <a href="https://knmnyn.github.io/cs3244-2210/">CS3244 Machine Learning, Fall 2022</a>-->
<!--              </br>-->
<!--              CS5478 Intelligent Robots: Algorithms and Systems, Spring 2023-->
            </td>
          </tr>

<!--          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr>-->
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Modified from <a href="https://jonbarron.info/">Jon Barron's site</a>. Last update: Mar 19, 2023
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
