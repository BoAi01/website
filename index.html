<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
      body {
          width: 45%;
          margin: 0 auto; /* Center the body horizontally */
      }
      .underline-on-hover {
        text-decoration: none;
        color: black;
      }
      .underline-on-hover:hover {   /* underline text when mouse hovering */
        text-decoration: underline;
        color: black;
      }
      div {      /* auto wrap and indent the second line */
        padding-left: 2.8em;
        text-indent: -2.8em;
      }
  </style>

  <title>Bo Ai</title>
  <meta name="author" content="Bo Ai">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="general_images/nus-logo-small.png">
</head>


<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YDE6X29CCQ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-YDE6X29CCQ');
</script>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<!--    <tr style="padding:10px">-->
<!--      <td style="padding:0px">-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Bo Ai</name>
              </p>
              <p>
                I am an undergraduate in Computer Science and Statistics under the Turing Program, <a href="https://nus.edu.sg/">National University of Singapore (NUS)</a>. I work at the intersection of robotics, machine learning, and computer vision, with the goal of enabling robots to act intelligently in the <em>real</em> world.
              </p>
              <p>
                Currently, I am working on visual-tactile perception for object manipulation at the <a href="https://svl.stanford.edu/">Stanford Vision and Learning Lab (SVL)</a>, advised by <a href="https://yunzhuli.github.io/">Yunzhu Li</a> and <a href="https://jiajunwu.com/">Jiajun Wu</a>. Previously, I worked with <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a> on low-level control and system architecture design for long-horizon visual navigation. In my earliest undergrad years, I explored video-based action recognition under <a href="https://www.comp.nus.edu.sg/~ayao/">Angela Yao</a>.
              </p>
<!--              <p>-->
<!--                At NUS, I received the <a href="https://www.comp.nus.edu.sg/news/2022-ourp-ocp-2122/">NUS Outstanding Undergraduate Research Prize</a> and the <a href="https://www.comp.nus.edu.sg/entrepreneurship/awards/iawinners/">NUS School of Computing Innovation Prize</a>.-->
<!--              </p>-->
              <p style="text-align:center">
                <a href="mailto:bo.ai@u.nus.edu">Email</a> &nbsp/&nbsp
<!--                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp-->
<!--                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.com/citations?user=KlE77HAAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
<!--                <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp-->
                <a href="https://github.com/BoAi01">GitHub</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/bo-ai/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:1.5%;width:20%;max-width:20%">
              <a href="general_images/linkedin-pic.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="general_images/linkedin-pic.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <heading>Research</heading>
              <p>
                More in progress...
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


<!-- highlighted papers should use bgcolor="#ffffd0" -->

<tr>
  <td style="padding:0px;width:15%;vertical-align:middle">
    <div class="one">
      <div class="two" id='tidy_image'><video  width=100% height=100% muted autoplay loop>
      <source src="projects/llm-tidy-rssw/LLM-TAMP-RSSW.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video>
      </div>
    </div>
  </td>
  <td style="padding:20px;width:85%;vertical-align:middle">
    <a href="https://openreview.net/pdf?id=vuSI9mhDaBZ">
      <papertitle>Integrating Common Sense and Planning with Large Language Models for Room Tidying</papertitle>
    </a>
    <br>
      Zhanxin Wu,
      <strong>Bo Ai</strong>,
      <a href="https://www.comp.nus.edu.sg/~dyhsu/" class="underline-on-hover">David Hsu</a>
    <br>

    <em><a href="https://zt-yang.github.io/rss23-l4tamp-workshop/" class="underline-on-hover">Robotics: Science and Systems (RSS) Workshop on Learning for Task and Motion Planning</a></em>, 2023 <br>

    <a href="https://openreview.net/pdf?id=vuSI9mhDaBZ">Paper</a>
    <p>
    A framework that enables an agent to put out-of-place objects back in place with partial map information by exploiting commonsense knowledge in large language models (LLMs).
    </p>
  </td>
</tr>

<tr bgcolor="#ffffd0">
  <td style="padding:0px;width:15%;vertical-align:middle">
    <div class="one">
      <div class="two" id='decision_image'><video  width=100% height=100% muted autoplay loop>
      <source src="projects/decision/decision-demo.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
    </div>
  </td>

  <td style="padding:20px;width:85%;vertical-align:middle">
    <a href="https://adacomp.comp.nus.edu.sg/inet/">
      <papertitle>Deep Visual Navigation under Partial Observability</papertitle>
    </a>

    <br>
    <strong>Bo Ai</strong>,
    <a href="https://www.linkedin.com/in/wei-gao-9526a477/?originalSubdomain=sg" class="underline-on-hover">Wei Gao</a>,
    <a href="https://connect.vin/about/" class="underline-on-hover">Vinay</a>,
    <a href="https://www.comp.nus.edu.sg/~dyhsu/" class="underline-on-hover">David Hsu</a>
    <br>

    <em>International Conference on Robotics and Automation (ICRA)</em>, 2022
    <br>
    <a href="https://adacomp.comp.nus.edu.sg/inet/">Project page</a> /
    <a href="https://arxiv.org/abs/2109.07752">Paper</a> /
    <a href="https://www.youtube.com/watch?v=N0wa04ZPZN0">Demo</a> /
    <a href="https://github.com/AdaCompNUS/DECISION">Code</a>

    <p>
    A learned controller that enables our Spot robot to navigate across varied environments with complex multimodal behaviors under partial observations.
    </p>
  </td>
</tr>

<tr>
  <td style="padding:0px;width:15%;vertical-align:middle">
    <div class="one">
      <div class="two" id='contrax_image'><video width=80% height=80% muted autoplay loop>
      <source src="" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <div style="text-align: center;">
      <img src="projects/contrax/visualization.png" width="90%" alt="Visualization">
      </div>
    </div>

  </td>
  <td style="padding:20px;width:85%;vertical-align:middle">
    <a href="https://aclanthology.org/2022.aacl-main.84">
      <papertitle>Whodunit? Learning to Contrast for Authorship Attribution</papertitle>
    </a>

    <br>
    <strong>Bo Ai</strong>, Yuchen Wang, Yugin Tan,
    <a href="https://samsontmr.github.io/" class="underline-on-hover">Samson Tan</a>
    <br>
    <em>Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and International Joint Conference on Natural Language Processing (AACL-IJCNLP, Long Paper)</em>, 2022
    <br>

    <a href="https://aclanthology.org/2022.aacl-main.84/">Paper</a> /
    <a href="https://www.youtube.com/watch?v=DpT181KgYlI">Talk</a> /
    <a href="https://github.com/BoAi01/Contra-X">Code</a>

    <p>
    Contrastive learning enables learning author-specific representations, which in turn improves authorship identification performance.
    </p>
  </td>
</tr>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
<heading>Academic Service</heading>
<td width="75%" valign="center">
  Reviewer, RA-L, IROS 2023, ICRA 2023, IROS 2022, ICRA 2022
</td>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
<heading>Teaching</heading>
<tr>
  <td width="100%" valign="center">
    <a href="https://www.comp.nus.edu.sg/~cs1101s/" class="underline-on-hover">CS1101S Programming Methodology, Fall 2020</a>
    </br>
    <a href="https://knmnyn.github.io/cs3244-2210/" class="underline-on-hover">CS3244 Machine Learning, Fall 2022</a>
    </br>
    CS5478 Intelligent Robots: Algorithms and Systems, Spring 2023
  </td>
</tr>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
<heading>Awards and Honors</heading>
  <tr>
    <td width="100%" valign="center">
    <div>2023: Dean's List (5%), NUS School of Computing </div>
    <div>2023: Global Young Scientists Summit 2023, Singapore National Research Foundation </div>
    <div>2022: <a href="https://www.comp.nus.edu.sg/news/2022-ourp-ocp-2122/" class="underline-on-hover">NUS Outstanding Undergraduate Research Prize</a> (0.4%), NUS </div>
    <div>2022: <a href="https://www.comp.nus.edu.sg/entrepreneurship/awards/iawinners/" class="underline-on-hover">NUS School of Computing Innovation Prize</a> (0.2%), NUS School of Computing & Singapore Computer Society </div>
    <div>2022: Certificate of Distinction in AI, NUS School of Computing </div>
    <div>2022: Certificate for Top Students x 2, NUS School of Computing </div>
    <div>2021: Certificate for Top Students x 1, NUS School of Computing </div>
    <div> 2018: NUS Science and Technology Scholarship, NUS & Singapore Ministry of Education </div>
    </td>
  </tr>


</tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
  <tr>
    <td style="padding:0px">
      <br>
      <p style="text-align:right;font-size:small;">
        Template from <a href="https://jonbarron.info/" class="underline-on-hover">Jon Barron</a>. Last updated: June 15, 2023
      </p>
    </td>
  </tr>
  </tbody>
</table>

</body>
</html>
